<HTML>



<HEAD>

<TITLE>Putnam 55/B6 solution</TITLE>

</HEAD>



<BODY TEXT="#000000" LINK="#0000ff" VLINK="#800080" ALINK="#ff0000">

<h3>15th Putnam 1955</h3>

<IMG src="../../line1.gif" ALT="------"><br>&nbsp;<br>&nbsp;<br>

<b>Problem B6</b><br>

<p>

Let N be the set of positive integers and R<sup>+</sup> the positive reals. f <b>:</b> N &rarr; R<sup>+</sup> satisfies f(n) &rarr; 0 as n &rarr; &infin;. Show that there are only finitely many solutions to f(a) + f(b) + f(c) = 1.

<p>

&nbsp;<p>

<b>Solution</b><br>

<p>

We show first that there are only finitely many solutions to f(a) + f(b) = k (&gt; 0). Take a to be &lt; b. Since f(n) &rarr; 0 we can find N such that f(n) &lt; k/2 for n &gt; N. So a must be &le; N. Now for each such a<sub>0</sub>, we can find M such that f(n) &lt; k - f(a<sub>0</sub>) for n &ge; M, so there are only finitely many b such that f(a<sub>0</sub>) + f(b) = k. Hence there are only finitely many solutions to f(a) + f(b) = k.

<p>

Now consider f(a) + f(b) + f(c) = 1. We can find N such that f(n) &lt; 1/3 for n &gt; N. So at least one of a, b, c must be &le; N. But for each such a we then have only finitely many solutions to f(b) + f(c) = 1 - f(a). Hence there are only finitely many solutions in total.

<p>

&nbsp;<p>

<IMG SRC="../../line2.gif" WIDTH=100% HEIGHT="2"><br>

<p>

&nbsp;<p>

<a href="../putn55.html">15th Putnam 1955</a><br>

<p>&copy; John Scholes<br>

jscholes@kalva.demon.co.uk<br>

25 Feb 2002

</BODY>



</HTML>

